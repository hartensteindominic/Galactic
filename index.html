<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Gesture-Master Local AI</title>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/hands"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils"></script>
    <style>
        :root { --glow: #00ff66; --bg: #050505; }
        body { background: var(--bg); color: white; font-family: 'Courier New', monospace; display: flex; flex-direction: column; align-items: center; justify-content: center; height: 100vh; margin: 0; }
        
        #ai-orb { 
            width: 250px; height: 250px; border-radius: 50%; 
            border: 5px solid var(--glow); box-shadow: 0 0 40px var(--glow);
            position: relative; overflow: hidden; margin-bottom: 30px;
            transition: border-color 0.5s, box-shadow 0.5s;
        }
        video { width: 100%; height: 100%; object-fit: cover; filter: contrast(1.5) brightness(0.8); }
        
        .hud { text-align: center; border: 1px solid #333; padding: 20px; border-radius: 10px; width: 400px; }
        #gesture-status { color: var(--glow); font-weight: bold; margin-bottom: 10px; }
        button { background: var(--glow); border: none; padding: 12px 24px; cursor: pointer; font-weight: bold; }
    </style>
</head>
<body>

<div id="ai-orb">
    <video id="webcam" autoplay playsinline></video>
</div>

<div class="hud">
    <div id="gesture-status">GESTURE SYSTEM: STANDBY</div>
    <button onclick="startAI()">INITIALIZE CORE</button>
    <p id="ai-talk" style="margin-top: 15px; font-size: 0.9rem;"></p>
</div>

<script>
    const video = document.getElementById('webcam');
    const status = document.getElementById('gesture-status');
    const aiTalk = document.getElementById('ai-talk');
    const orb = document.getElementById('ai-orb');

    const hands = new Hands({locateFile: (file) => `https://cdn.jsdelivr.net/npm/@hands-detection/hands/${file}`});
    hands.setOptions({ maxNumHands: 1, modelComplexity: 1, minDetectionConfidence: 0.7 });
    
    hands.onResults(results => {
        if (results.multiHandLandmarks && results.multiHandLandmarks.length > 0) {
            status.innerText = "GESTURE DETECTED: ACTIVE";
            // Change color to 'Power Mode' (Orange) when hand is visible
            document.documentElement.style.setProperty('--glow', '#ff9900');
            if (!window.speechSynthesis.speaking) {
                speak("I see your hand. Ready for commands.");
            }
        } else {
            status.innerText = "GESTURE SYSTEM: SCANNING...";
            document.documentElement.style.setProperty('--glow', '#00ff66');
        }
    });

    async function startAI() {
        const stream = await navigator.mediaDevices.getUserMedia({ video: true });
        video.srcObject = stream;
        
        const camera = new Camera(video, {
            onFrame: async () => { await hands.send({image: video}); },
            width: 640, height: 480
        });
        camera.start();
        speak("Core initialized. I am watching for your movements.");
    }

    function speak(text) {
        aiTalk.innerText = text;
        const msg = new SpeechSynthesisUtterance(text);
        msg.pitch = 0.7;
        window.speechSynthesis.speak(msg);
    }
</script>
</body>
</html>
